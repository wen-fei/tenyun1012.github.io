<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>graph-embeddings-papers-list</title>
      <link href="/2019/11/18/graph-embeddings-papers-list/"/>
      <url>/2019/11/18/graph-embeddings-papers-list/</url>
      
        <content type="html"><![CDATA[<h1 id="awesome-network-embedding"><a href="#awesome-network-embedding" class="headerlink" title="awesome-network-embedding"></a>awesome-network-embedding</h1><blockquote><p>原库地址：<a href="https://github.com/chihming/awesome-network-embedding" target="_blank" rel="noopener">https://github.com/chihming/awesome-network-embedding</a></p></blockquote><p><a href="https://github.com/sindresorhus/awesome" target="_blank" rel="noopener"><img src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg" alt="Awesome"></a><br><a href="http://makeapullrequest.com" target="_blank" rel="noopener"><img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square" alt="PRs Welcome"></a><br><a href="https://gitter.im/awesome-network-embedding/Lobby" target="_blank" rel="noopener"><img src="https://badges.gitter.im/Join%20Chat.svg" alt="Gitter chat for developers at https://gitter.im/dmlc/xgboost"></a></p><p>Also called network representation learning, graph embedding, knowledge embedding, etc.</p><p>The task is to learn the representations of the vertices from a given network.</p><p>CALL FOR HELP: I’m planning to re-organize the papers with clear classification index in the near future. Please feel free to submit a commit if you find any interesting related work:)</p><img src="https://user-images.githubusercontent.com/8847689/69019860-74d16300-09ed-11ea-968f-5cb696336084.png" width="480"><h2 id="Paper-References-with-the-implementation-s"><a href="#Paper-References-with-the-implementation-s" class="headerlink" title="Paper References with the implementation(s)"></a>Paper References with the implementation(s)</h2><ul><li><strong>GEMSEC</strong><ul><li>GEMSEC: Graph Embedding with Self Clustering, ASONAM 2019</li><li><a href="https://arxiv.org/abs/1802.03997" target="_blank" rel="noopener">[Paper]</a></li><li><a href="https://github.com/benedekrozemberczki/GEMSEC" target="_blank" rel="noopener">[Python]</a> </li></ul></li><li><strong>AmpliGraph</strong><ul><li>Library for learning knowledge graph embeddings with TensorFlow </li><li><a href="http://docs.ampligraph.org" target="_blank" rel="noopener">[Project]</a></li><li><a href="https://github.com/Accenture/AmpliGraph" target="_blank" rel="noopener">[code]</a></li></ul></li><li><strong>jodie</strong><ul><li>Predicting Dynamic Embedding Trajectory in Temporal Interaction Networks, KDD’19</li><li><a href="http://snap.stanford.edu/jodie/" target="_blank" rel="noopener">[Project]</a></li><li><a href="https://github.com/srijankr/jodie/" target="_blank" rel="noopener">[Code]</a></li></ul></li><li><strong>PyTorch-BigGraph</strong><ul><li>Pytorch-BigGraph - a distributed system for learning graph embeddings for large graphs, SysML’19</li><li><a href="https://github.com/facebookresearch/PyTorch-BigGraph" target="_blank" rel="noopener">[github]</a></li></ul></li><li><strong>ATP</strong><ul><li>ATP: Directed Graph Embedding with Asymmetric Transitivity Preservation, AAAI’19</li><li><a href="https://arxiv.org/abs/1811.00839" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/zhenv5/atp" target="_blank" rel="noopener">[code]</a></li></ul></li><li><strong>MUSAE</strong><ul><li>Multi-scale Attributed Node Embedding, ArXiv 2019</li><li><a href="https://arxiv.org/abs/1909.13021" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/benedekrozemberczki/MUSAE" target="_blank" rel="noopener">[Python]</a></li></ul></li><li><strong>SEAL-CI</strong><ul><li>Semi-Supervised Graph Classification: A Hierarchical Graph Perspective, WWW’19</li><li><a href="https://arxiv.org/pdf/1904.05003.pdf" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/benedekrozemberczki/SEAL-CI" target="_blank" rel="noopener">[Python PyTorch]</a></li></ul></li><li><strong>N-GCN</strong><ul><li>A Higher-Order Graph Convolutional Layer, NIPS’18 (workshop)</li><li><a href="http://sami.haija.org/papers/high-order-gc-layer.pdf" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/benedekrozemberczki/MixHop-and-N-GCN" target="_blank" rel="noopener">[Python PyTorch]</a></li></ul></li><li><strong>CapsGNN</strong><ul><li>Capsule Graph Neural Network, ICLR’19</li><li><a href="https://openreview.net/forum?id=Byl8BnRcYm" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/benedekrozemberczki/CapsGNN" target="_blank" rel="noopener">[Python PyTorch]</a></li></ul></li><li><strong>Splitter</strong><ul><li>Splitter: Learning Node Representations that Capture Multiple Social Contexts, WWW’19</li><li><a href="http://epasto.org/papers/www2019splitter.pdf" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/benedekrozemberczki/Splitter" target="_blank" rel="noopener">[Python PyTorch]</a></li></ul></li><li><strong>REGAL</strong><ul><li>REGAL: Representation Learning-based Graph Alignment. International Conference on Information and Knowledge Management, CIKM’18</li><li><a href="https://arxiv.org/pdf/1802.06257.pdf" target="_blank" rel="noopener">[arxiv]</a></li><li><a href="https://dl.acm.org/citation.cfm?id=3271788" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/GemsLab/REGAL" target="_blank" rel="noopener">[code]</a></li></ul></li><li><strong>PyTorch Geometric</strong><ul><li>Fast Graph Representation Learning With PyTorch Geometric</li><li><a href="https://arxiv.org/pdf/1903.02428.pdf" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/rusty1s/pytorch_geometric" target="_blank" rel="noopener">[Python PyTorch]</a></li></ul></li><li><strong>TuckER</strong><ul><li>Tensor Factorization for Knowledge Graph Completion, Arxiv’19</li><li><a href="https://arxiv.org/pdf/1901.09590.pdf" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/ibalazevic/TuckER" target="_blank" rel="noopener">[Python PyTorch]</a></li></ul></li><li><strong>HypER</strong><ul><li>Hypernetwork Knowledge Graph Embeddings, Arxiv’18</li><li><a href="https://arxiv.org/pdf/1808.07018.pdf" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/ibalazevic/HypER" target="_blank" rel="noopener">[Python PyTorch]</a></li></ul></li><li><strong>GWNN</strong><ul><li>Graph Wavelet Neural Network, ICLR’19</li><li><a href="https://openreview.net/forum?id=H1ewdiR5tQ" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/benedekrozemberczki/GraphWaveletNeuralNetwork" target="_blank" rel="noopener">[Python PyTorch]</a></li><li><a href="https://github.com/Eilene/GWNN" target="_blank" rel="noopener">[Python TensorFlow]</a></li></ul></li><li><strong>APPNP</strong><ul><li>Combining Neural Networks with Personalized PageRank for Classification on Graphs, ICLR’19</li><li><a href="https://arxiv.org/abs/1810.05997" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/benedekrozemberczki/APPNP" target="_blank" rel="noopener">[Python PyTorch]</a></li><li><a href="https://github.com/klicperajo/ppnp" target="_blank" rel="noopener">[Python TensorFlow]</a></li></ul></li><li><strong>role2vec</strong><ul><li>Learning Role-based Graph Embeddings, IJCAI’18</li><li><a href="https://arxiv.org/pdf/1802.02896.pdf" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/benedekrozemberczki/role2vec" target="_blank" rel="noopener">[Python]</a></li></ul></li><li><strong>AttentionWalk</strong><ul><li>Watch Your Step: Learning Node Embeddings via Graph Attention, NIPS’18</li><li><a href="https://arxiv.org/pdf/1710.09599.pdf" target="_blank" rel="noopener">[paper]</a></li><li><a href="http://sami.haija.org/graph/context" target="_blank" rel="noopener">[Python]</a></li><li><a href="https://github.com/benedekrozemberczki/AttentionWalk" target="_blank" rel="noopener">[Python PyTorch]</a></li><li><a href="https://github.com/google-research/google-research/tree/master/graph_embedding/watch_your_step/" target="_blank" rel="noopener">[Python TensorFlow]</a></li></ul></li><li><strong>GAT</strong><ul><li>Graph Attention Networks, ICLR’18</li><li><a href="https://arxiv.org/pdf/1710.10903.pdf" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/Diego999/pyGAT" target="_blank" rel="noopener">[Python PyTorch]</a></li><li><a href="https://github.com/PetarV-/GAT" target="_blank" rel="noopener">[Python TensorFlow]</a></li></ul></li><li><strong>SINE</strong><ul><li>SINE: Scalable Incomplete Network Embedding, ICDM’18</li><li><a href="https://github.com/benedekrozemberczki/SINE/blob/master/paper.pdf" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/benedekrozemberczki/SINE/" target="_blank" rel="noopener">[Python PyTorch]</a></li><li><a href="https://github.com/daokunzhang/SINE" target="_blank" rel="noopener">[C++]</a></li></ul></li><li><strong>SGCN</strong><ul><li>Signed Graph Convolutional Network, ICDM’18</li><li><a href="https://github.com/benedekrozemberczki/SGCN/blob/master/sgcn.pdf" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/benedekrozemberczki/SGCN" target="_blank" rel="noopener">[Python]</a></li></ul></li><li><strong>TENE</strong><ul><li>Enhanced Network Embedding with Text Information, ICPR’18</li><li><a href="https://github.com/benedekrozemberczki/TENE/blob/master/tene_paper.pdf" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/benedekrozemberczki/TENE" target="_blank" rel="noopener">[Python]</a> </li></ul></li><li><strong>DANMF</strong><ul><li>Deep Autoencoder-like Nonnegative Matrix Factorization for Community Detection, CIKM’18</li><li><a href="https://smartyfh.com/Documents/18DANMF.pdf" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/benedekrozemberczki/DANMF" target="_blank" rel="noopener">[Python]</a></li><li><a href="https://github.com/smartyfh/DANMF" target="_blank" rel="noopener">[Matlab]</a>  </li></ul></li><li><strong>BANE</strong><ul><li>Binarized Attributed Network Embedding, ICDM’18</li><li><a href="https://www.researchgate.net/publication/328688614_Binarized_Attributed_Network_Embedding" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/benedekrozemberczki/BANE" target="_blank" rel="noopener">[Python]</a></li><li><a href="https://github.com/ICDM2018-BANE/BANE" target="_blank" rel="noopener">[Matlab]</a></li></ul></li><li><strong>GCN Insights</strong><ul><li>Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning, AAAI’18</li><li><a href="https://liqimai.github.io/blog/AAAI-18/" target="_blank" rel="noopener">[Project]</a></li><li><a href="https://github.com/liqimai/gcn/tree/AAAI-18/" target="_blank" rel="noopener">[code]</a></li></ul></li><li><strong>PCTADW</strong><ul><li>Learning Embeddings of Directed Networks with Text-Associated Nodes—with Applications in Software Package Dependency Networks</li><li><a href="https://arxiv.org/pdf/1809.02270.pdf" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/shudan/PCTADW" target="_blank" rel="noopener">[Python]</a></li><li><a href="https://doi.org/10.5281/zenodo.1410669" target="_blank" rel="noopener">[dataset]</a></li></ul></li><li><strong>LGCN</strong><ul><li>Large-Scale Learnable Graph Convolutional Networks, KDD’18</li><li><a href="http://www.kdd.org/kdd2018/accepted-papers/view/large-scale-learnable-graph-convolutional-networks" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/HongyangGao/LGCN" target="_blank" rel="noopener">[Python]</a></li></ul></li><li><strong>AspEm</strong><ul><li>AspEm: Embedding Learning by Aspects in Heterogeneous Information Networks</li><li><a href="http://yushi2.web.engr.illinois.edu/sdm18.pdf" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/ysyushi/aspem" target="_blank" rel="noopener">[Python]</a></li></ul></li><li><strong>Walklets</strong><ul><li>Don’t Walk, Skip! Online Learning of Multi-scale Network Embeddings</li><li><a href="https://arxiv.org/pdf/1605.02115.pdf" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/benedekrozemberczki/walklets" target="_blank" rel="noopener">[Python]</a>  </li></ul></li><li><strong>gat2vec</strong><ul><li>gat2vec: Representation learning for attributed graphs</li><li><a href="https://doi.org/10.1007/s00607-018-0622-9" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/snash4/GAT2VEC" target="_blank" rel="noopener">[Python]</a></li></ul></li><li><strong>FSCNMF</strong><ul><li>FSCNMF: Fusing Structure and Content via Non-negative Matrix Factorization for Embedding Information Networks</li><li><a href="https://arxiv.org/abs/1804.05313" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/sambaranban/FSCNMF" target="_blank" rel="noopener">[Python]</a>  </li><li><a href="https://github.com/benedekrozemberczki/FSCNMF" target="_blank" rel="noopener">[Python]</a></li></ul></li><li><strong>SIDE</strong><ul><li>SIDE: Representation Learning in Signed Directed Networks</li><li><a href="https://datalab.snu.ac.kr/side/resources/side.pdf" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://datalab.snu.ac.kr/side/resources/side.zip" target="_blank" rel="noopener">[Python]</a></li><li><a href="https://datalab.snu.ac.kr/side/" target="_blank" rel="noopener">[Site]</a></li></ul></li><li><strong>AWE</strong><ul><li>Anonymous Walk Embeddings, ICML’18</li><li><a href="https://www.researchgate.net/publication/325114285_Anonymous_Walk_Embeddings" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/nd7141/Anonymous-Walk-Embeddings" target="_blank" rel="noopener">[Python]</a></li></ul></li><li><strong>BiNE</strong><ul><li>BiNE: Bipartite Network Embedding, SIGIR’18</li><li><a href="http://staff.ustc.edu.cn/~hexn/papers/sigir18-bipartiteNE.pdf" target="_blank" rel="noopener">[paper]</a></li><li><a href="https://github.com/clhchtcjj/BiNE" target="_blank" rel="noopener">[Python]</a></li></ul></li><li><strong>HOPE</strong><ul><li>Asymmetric Transitivity Preserving Graph Embedding</li><li><a href="http://www.kdd.org/kdd2016/papers/files/rfp0184-ouA.pdf" target="_blank" rel="noopener">[KDD 2016]</a></li><li><a href="https://github.com/AnryYang/HOPE" target="_blank" rel="noopener">[Python]</a> </li></ul></li><li><strong>VERSE</strong><ul><li>VERSE, Versatile Graph Embeddings from Similarity Measures</li><li><a href="https://arxiv.org/abs/1803.04742" target="_blank" rel="noopener">[Arxiv]</a> [[WWW 2018]]</li><li><a href="https://github.com/xgfs/verse" target="_blank" rel="noopener">[Python]</a> </li></ul></li><li><strong>AGNN</strong><ul><li>Attention-based Graph Neural Network for semi-supervised learning</li><li><a href="https://openreview.net/forum?id=rJg4YGWRb" target="_blank" rel="noopener">[ICLR 2018 OpenReview (rejected)]</a></li><li><a href="https://github.com/dawnranger/pytorch-AGNN" target="_blank" rel="noopener">[Python]</a></li></ul></li><li><strong>SEANO</strong><ul><li>Semi-supervised Embedding in Attributed Networks with Outliers</li><li><a href="https://arxiv.org/pdf/1703.08100.pdf" target="_blank" rel="noopener">[Paper]</a> (SDM 2018)</li><li><a href="http://jiongqianliang.com/SEANO/" target="_blank" rel="noopener">[Python]</a>   </li></ul></li><li><strong>Hyperbolics</strong><ul><li>Representation Tradeoffs for Hyperbolic Embeddings </li><li><a href="https://arxiv.org/abs/1804.03329" target="_blank" rel="noopener">[Arxiv]</a></li><li><a href="https://github.com/HazyResearch/hyperbolics" target="_blank" rel="noopener">[Python]</a>   </li></ul></li><li><strong>DGCNN</strong><ul><li>An End-to-End Deep Learning Architecture for Graph Classiﬁcation </li><li><a href="http://www.cse.wustl.edu/~muhan/papers/AAAI_2018_DGCNN.pdf" target="_blank" rel="noopener">[AAAI 2018]</a></li><li><a href="https://github.com/muhanzhang/DGCNN" target="_blank" rel="noopener">[Lua]</a> <a href="https://github.com/muhanzhang/pytorch_DGCNN" target="_blank" rel="noopener">[Python]</a>  </li></ul></li><li><strong>structure2vec</strong><ul><li>Discriminative Embeddings of Latent Variable Models for Structured Data </li><li><a href="https://arxiv.org/abs/1603.05629" target="_blank" rel="noopener">[Arxiv]</a></li><li><a href="https://github.com/Hanjun-Dai/pytorch_structure2vec" target="_blank" rel="noopener">[Python]</a>  </li></ul></li><li><strong>Decagon</strong><ul><li>Decagon, Graph Neural Network for Multirelational Link Prediction </li><li><a href="https://arxiv.org/abs/1802.00543" target="_blank" rel="noopener">[Arxiv]</a> <a href="http://snap.stanford.edu/decagon/" target="_blank" rel="noopener">[SNAP]</a> [[ISMB 2018]]</li><li><a href="https://github.com/marinkaz/decagon" target="_blank" rel="noopener">[Python]</a>    </li></ul></li><li><strong>DHNE</strong><ul><li>Structural Deep Embedding for Hyper-Networks</li><li><a href="http://nrl.thumedialab.com/Structural-Deep-Embedding-for-Hyper-Networks" target="_blank" rel="noopener">[AAAI 2018]</a><a href="https://arxiv.org/abs/1711.10146" target="_blank" rel="noopener">[Arxiv]</a></li><li><a href="https://github.com/tadpole/DHNE" target="_blank" rel="noopener">[Python]</a>  </li></ul></li><li><strong>Ohmnet</strong><ul><li>Feature Learning in Multi-Layer Networks </li><li><a href="https://arxiv.org/abs/1707.04638" target="_blank" rel="noopener">[Arxiv]</a> <a href="http://snap.stanford.edu/ohmnet/" target="_blank" rel="noopener">[SNAP]</a> </li><li><a href="https://github.com/marinkaz/ohmnet" target="_blank" rel="noopener">[Python]</a>  </li></ul></li><li><strong>SDNE</strong><ul><li>Structural Deep Network Embedding </li><li><a href="http://www.kdd.org/kdd2016/papers/files/rfp0191-wangAemb.pdf" target="_blank" rel="noopener">[KDD 2016]</a></li><li><a href="https://github.com/xiaohan2012/sdne-keras" target="_blank" rel="noopener">[Python]</a> </li></ul></li><li><strong>STWalk</strong><ul><li>STWalk: Learning Trajectory Representations in Temporal Graphs] </li><li><a href="https://arxiv.org/abs/1711.04150" target="_blank" rel="noopener">[Arxiv]</a></li><li><a href="https://github.com/supriya-pandhre/STWalk" target="_blank" rel="noopener">[Python]</a></li></ul></li><li><strong>LoNGAE</strong><ul><li>Learning to Make Predictions on Graphs with Autoencoders </li><li><a href="https://arxiv.org/abs/1802.08352" target="_blank" rel="noopener">[Arxiv]</a></li><li><a href="https://github.com/vuptran/graph-representation-learning" target="_blank" rel="noopener">[Python]</a>  </li></ul></li><li><strong>RSDNE</strong><ul><li><a href="https://zhengwang100.github.io/AAAI18_RSDNE.pdf" target="_blank" rel="noopener">RSDNE: Exploring Relaxed Similarity and Dissimilarity from Completely-imbalanced Labels for Network Embedding.</a>, AAAI 2018</li><li><a href="https://github.com/zhengwang100/RSDNE" target="_blank" rel="noopener">[Matlab]</a> </li></ul></li><li><strong>FastGCN</strong><ul><li>FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling </li><li><a href="https://arxiv.org/abs/1801.10247" target="_blank" rel="noopener">[Arxiv]</a>, <a href="https://openreview.net/forum?id=rytstxWAW" target="_blank" rel="noopener">[ICLR 2018 OpenReview]</a></li><li><a href="https://github.com/matenure/FastGCN" target="_blank" rel="noopener">[Python]</a></li></ul></li><li><strong>diff2vec</strong><ul><li><a href="http://homepages.inf.ed.ac.uk/s1668259/papers/sequence.pdf" target="_blank" rel="noopener">Fast Sequence Based Embedding with Diffusion Graphs</a>, CompleNet 2018</li><li><a href="https://github.com/benedekrozemberczki/diff2vec" target="_blank" rel="noopener">[Python]</a> </li></ul></li><li><strong>Poincare</strong><ul><li><a href="https://papers.nips.cc/paper/7213-poincare-embeddings-for-learning-hierarchical-representations" target="_blank" rel="noopener">Poincaré Embeddings for Learning Hierarchical Representations</a>, NIPS 2017</li><li><a href="https://github.com/facebookresearch/poincare-embeddings" target="_blank" rel="noopener">[PyTorch]</a> <a href="https://radimrehurek.com/gensim/models/poincare.html" target="_blank" rel="noopener">[Python]</a> <a href="https://github.com/TatsuyaShirakawa/poincare-embedding" target="_blank" rel="noopener">[C++]</a></li></ul></li><li><strong>PEUNE</strong><ul><li><a href="https://papers.nips.cc/paper/7110-prune-preserving-proximity-and-global-ranking-for-network-embedding" target="_blank" rel="noopener">PRUNE: Preserving Proximity and Global Ranking for Network Embedding</a>, NIPS 2017</li><li><a href="https://github.com/ntumslab/PRUNE" target="_blank" rel="noopener">[code]</a></li></ul></li><li><strong>ASNE</strong><ul><li>Attributed Social Network Embedding, arxiv’17</li><li><a href="https://arxiv.org/abs/1706.01860" target="_blank" rel="noopener">[arxiv]</a></li><li><a href="https://github.com/lizi-git/ASNE" target="_blank" rel="noopener">[Python]</a></li><li><a href="https://github.com/benedekrozemberczki/ASNE" target="_blank" rel="noopener">[Fast Python]</a></li></ul></li><li><strong>GraphWave</strong><ul><li><a href="http://snap.stanford.edu/graphwave/" target="_blank" rel="noopener">Spectral Graph Wavelets for Structural Role Similarity in Networks</a>, </li><li><a href="https://arxiv.org/abs/1710.10321" target="_blank" rel="noopener">[arxiv]</a>, <a href="https://openreview.net/forum?id=rytstxWAW" target="_blank" rel="noopener">[ICLR 2018 OpenReview]</a></li><li><a href="https://github.com/snap-stanford/graphwave" target="_blank" rel="noopener">[Python]</a> <a href="https://github.com/benedekrozemberczki/GraphWaveMachine" target="_blank" rel="noopener">[faster version]</a></li></ul></li><li><strong>StarSpace</strong><ul><li><a href="https://arxiv.org/pdf/1709.03856" target="_blank" rel="noopener">StarSpace: Embed All The Things!</a>, arxiv’17</li><li><a href="https://github.com/facebookresearch/Starspace" target="_blank" rel="noopener">[code]</a></li></ul></li><li><strong>proNet-core</strong><ul><li>Vertex-Context Sampling for Weighted Network Embedding, arxiv’17</li><li><a href="https://arxiv.org/abs/1711.00227" target="_blank" rel="noopener">[arxiv]</a> <a href="https://github.com/cnclabs/proNet-core" target="_blank" rel="noopener">[code]</a></li></ul></li><li><strong>struc2vec</strong><ul><li><a href="https://dl.acm.org/citation.cfm?id=3098061" target="_blank" rel="noopener">struc2vec: Learning Node Representations from Structural Identity</a>, KDD’17</li><li><a href="https://github.com/leoribeiro/struc2vec" target="_blank" rel="noopener">[Python]</a></li></ul></li><li><strong>ComE</strong><ul><li>Learning Community Embedding with Community Detection and Node Embedding on Graphs, CIKM’17</li><li><a href="https://github.com/andompesta/ComE" target="_blank" rel="noopener">[Python]</a></li></ul></li><li><strong>BoostedNE</strong><ul><li><a href="https://arxiv.org/abs/1808.08627" target="_blank" rel="noopener">Multi-Level Network Embedding with Boosted Low-Rank Matrix Approximation</a>, ‘18</li><li><a href="https://github.com/benedekrozemberczki/BoostedFactorization" target="_blank" rel="noopener">[Python]</a>  </li></ul></li><li><strong>M-NMF</strong><ul><li>Community Preserving Network Embedding, AAAI’17</li><li><a href="https://github.com/benedekrozemberczki/M-NMF" target="_blank" rel="noopener">[Python]</a></li></ul></li><li><strong>GraphSAGE</strong><ul><li>Inductive Representation Learning on Large Graphs, NIPS’17</li><li><a href="https://arxiv.org/abs/1706.02216" target="_blank" rel="noopener">[arxiv]</a> <a href="https://github.com/williamleif/GraphSAGE" target="_blank" rel="noopener">[TF]</a> <a href="https://github.com/williamleif/graphsage-simple/" target="_blank" rel="noopener">[PyTorch]</a> </li></ul></li><li><strong>ICE</strong><ul><li><a href="http://dl.acm.org/citation.cfm?id=3080807" target="_blank" rel="noopener">ICE: Item Concept Embedding via Textual Information</a>, SIGIR’17</li><li><a href="https://cnclabs.github.io/ICE/" target="_blank" rel="noopener">[demo]</a> <a href="https://github.com/cnclabs/ICE" target="_blank" rel="noopener">[code]</a></li></ul></li><li><strong>GuidedHeteEmbedding</strong><ul><li>Task-guided and path-augmented heterogeneous network embedding for author identification, WSDM’17</li><li><a href="https://arxiv.org/pdf/1612.02814.pdf" target="_blank" rel="noopener">[paper]</a> <a href="https://github.com/chentingpc/GuidedHeteEmbedding" target="_blank" rel="noopener">[code]</a></li></ul></li><li><strong>metapath2vec</strong><ul><li>metapath2vec: Scalable Representation Learning for Heterogeneous Networks, KDD’17</li><li><a href="https://www3.nd.edu/~dial/publications/dong2017metapath2vec.pdf" target="_blank" rel="noopener">[paper]</a> <a href="https://ericdongyx.github.io/metapath2vec/m2v.html" target="_blank" rel="noopener">[project website]</a></li></ul></li><li><strong>GCN</strong><ul><li>Semi-Supervised Classification with Graph Convolutional Networks, ICLR’17</li><li><a href="https://arxiv.org/abs/1609.02907" target="_blank" rel="noopener">[arxiv]</a>  <a href="https://github.com/tkipf/gcn" target="_blank" rel="noopener">[Python Tensorflow]</a></li></ul></li><li><strong>GAE</strong><ul><li>Variational Graph Auto-Encoders, arxiv</li><li><a href="https://arxiv.org/abs/1611.07308" target="_blank" rel="noopener">[arxiv]</a> <a href="https://github.com/tkipf/gae" target="_blank" rel="noopener">[Python Tensorflow]</a></li></ul></li><li><strong>CANE</strong><ul><li>CANE: Context-Aware Network Embedding for Relation Modeling, ACL’17</li><li><a href="http://www.thunlp.org/~tcc/publications/acl2017_cane.pdf" target="_blank" rel="noopener">[paper]</a> <a href="https://github.com/thunlp/cane" target="_blank" rel="noopener">[Python]</a></li></ul></li><li><strong>TransNet</strong><ul><li>TransNet: Translation-Based Network Representation Learning for Social Relation Extraction, IJCAI’17</li><li><a href="https://github.com/thunlp/TransNet" target="_blank" rel="noopener">[Python Tensorflow]</a></li></ul></li><li><strong>cnn_graph</strong><ul><li>Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering, NIPS’16</li><li><a href="https://github.com/mdeff/cnn_graph" target="_blank" rel="noopener">[Python]</a></li></ul></li><li><strong>ConvE</strong><ul><li><a href="https://arxiv.org/pdf/1707.01476v2.pdf" target="_blank" rel="noopener">Convolutional 2D Knowledge Graph Embeddings</a>, arxiv</li><li><a href="https://github.com/TimDettmers/ConvE" target="_blank" rel="noopener">[source]</a></li></ul></li><li><strong>node2vec</strong><ul><li><a href="http://dl.acm.org/citation.cfm?id=2939672.2939754" target="_blank" rel="noopener">node2vec: Scalable Feature Learning for Networks</a>, KDD’16</li><li><a href="https://arxiv.org/abs/1607.00653" target="_blank" rel="noopener">[arxiv]</a> <a href="https://github.com/aditya-grover/node2vec" target="_blank" rel="noopener">[Python]</a> <a href="https://github.com/apple2373/node2vec" target="_blank" rel="noopener">[Python-2]</a> <a href="https://github.com/eliorc/node2vec" target="_blank" rel="noopener">[Python-3]</a> <a href="https://github.com/xgfs/node2vec-c" target="_blank" rel="noopener">[C++]</a>  </li></ul></li><li><strong>DNGR</strong><ul><li><a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12423" target="_blank" rel="noopener">Deep Neural Networks for Learning Graph Representations</a>, AAAI’16</li><li><a href="https://github.com/ShelsonCao/DNGR" target="_blank" rel="noopener">[Matlab]</a> <a href="https://github.com/MdAsifKhan/DNGR-Keras" target="_blank" rel="noopener">[Python Keras]</a></li></ul></li><li><strong>HolE</strong><ul><li><a href="http://dl.acm.org/citation.cfm?id=3016172" target="_blank" rel="noopener">Holographic Embeddings of Knowledge Graphs</a>, AAAI’16</li><li><a href="https://github.com/mnick/holographic-embeddings" target="_blank" rel="noopener">[Python-sklearn]</a> <a href="https://github.com/mnick/scikit-kge" target="_blank" rel="noopener">[Python-sklearn2]</a></li></ul></li><li><strong>ComplEx</strong><ul><li><a href="http://dl.acm.org/citation.cfm?id=3045609" target="_blank" rel="noopener">Complex Embeddings for Simple Link Prediction</a>, ICML’16</li><li><a href="https://arxiv.org/abs/1606.06357" target="_blank" rel="noopener">[arxiv]</a> <a href="https://github.com/ttrouill/complex" target="_blank" rel="noopener">[Python]</a></li></ul></li><li><strong>MMDW</strong><ul><li>Max-Margin DeepWalk: Discriminative Learning of Network Representation, IJCAI’16</li><li><a href="http://nlp.csai.tsinghua.edu.cn/~lzy/publications/ijcai2016_mmdw.pdf" target="_blank" rel="noopener">[paper]</a>  <a href="https://github.com/thunlp/MMDW" target="_blank" rel="noopener">[Java]</a></li></ul></li><li><strong>planetoid</strong><ul><li>Revisiting Semi-supervised Learning with Graph Embeddings, ICML’16</li><li><a href="https://arxiv.org/abs/1603.08861" target="_blank" rel="noopener">[arxiv]</a> <a href="https://github.com/kimiyoung/planetoid" target="_blank" rel="noopener">[Python]</a></li></ul></li><li><strong>graph2vec</strong><ul><li>graph2vec: Learning Distributed Representations of Graphs, KDD’17 MLGWorkshop</li><li><a href="https://arxiv.org/abs/1707.05005" target="_blank" rel="noopener">[arxiv]</a> <a href="https://github.com/benedekrozemberczki/graph2vec" target="_blank" rel="noopener">[Python]</a></li></ul></li><li><strong>PowerWalk</strong><ul><li><a href="http://dl.acm.org/citation.cfm?id=2983713" target="_blank" rel="noopener">PowerWalk: Scalable Personalized PageRank via Random Walks with Vertex-Centric Decomposition</a>, CIKM’16</li><li><a href="https://github.com/lqhl/PowerWalk" target="_blank" rel="noopener">[code]</a></li></ul></li><li><strong>LINE</strong><ul><li><a href="http://dl.acm.org/citation.cfm?id=2741093" target="_blank" rel="noopener">LINE: Large-scale information network embedding</a>, WWW’15</li><li><a href="https://arxiv.org/abs/1503.03578" target="_blank" rel="noopener">[arxiv]</a> <a href="https://github.com/tangjianpku/LINE" target="_blank" rel="noopener">[C++]</a> <a href="https://github.com/snowkylin/line" target="_blank" rel="noopener">[Python TF]</a> <a href="https://github.com/VahidooX/LINE" target="_blank" rel="noopener">[Python Theano/Keras]</a></li></ul></li><li><strong>PTE</strong><ul><li><a href="http://dl.acm.org/citation.cfm?id=2783307" target="_blank" rel="noopener">PTE: Predictive Text Embedding through Large-scale Heterogeneous Text Networks</a>, KDD’15</li><li><a href="https://github.com/mnqu/PTE" target="_blank" rel="noopener">[C++]</a></li></ul></li><li><strong>GraRep</strong><ul><li><a href="http://dl.acm.org/citation.cfm?id=2806512" target="_blank" rel="noopener">Grarep: Learning graph representations with global structural information</a>, CIKM’15</li><li><a href="https://github.com/ShelsonCao/GraRep" target="_blank" rel="noopener">[Matlab]</a></li><li><a href="https://github.com/xgfs/GraRep.jl" target="_blank" rel="noopener">[Julia]</a></li><li><a href="https://github.com/benedekrozemberczki/GraRep" target="_blank" rel="noopener">[Python]</a></li></ul></li><li><strong>KB2E</strong><ul><li><a href="http://dl.acm.org/citation.cfm?id=2886624" target="_blank" rel="noopener">Learning Entity and Relation Embeddings for Knowledge Graph Completion</a>, AAAI’15</li><li><a href="http://nlp.csai.tsinghua.edu.cn/~lzy/publications/aaai2015_transr.pdf" target="_blank" rel="noopener">[paper]</a> <a href="https://github.com/thunlp/KB2E" target="_blank" rel="noopener">[C++]</a>  <a href="https://github.com/thunlp/Fast-TransX" target="_blank" rel="noopener">[faster version]</a></li></ul></li><li><strong>TADW</strong><ul><li><a href="http://dl.acm.org/citation.cfm?id=2832542" target="_blank" rel="noopener">Network Representation Learning with Rich Text Information</a>, IJCAI’15</li><li><a href="https://www.ijcai.org/Proceedings/15/Papers/299.pdf" target="_blank" rel="noopener">[paper]</a> <a href="https://github.com/thunlp/tadw" target="_blank" rel="noopener">[Matlab]</a> <a href="https://github.com/benedekrozemberczki/TADW" target="_blank" rel="noopener">[Python]</a></li></ul></li><li><strong>DeepWalk</strong><ul><li><a href="http://dl.acm.org/citation.cfm?id=2623732" target="_blank" rel="noopener">DeepWalk: Online Learning of Social Representations</a>, KDD’14</li><li><a href="https://arxiv.org/abs/1403.6652" target="_blank" rel="noopener">[arxiv]</a> <a href="https://github.com/phanein/deepwalk" target="_blank" rel="noopener">[Python]</a>  <a href="https://github.com/xgfs/deepwalk-c" target="_blank" rel="noopener">[C++]</a></li></ul></li><li><strong>GEM</strong><ul><li>Graph Embedding Techniques, Applications, and Performance: A Survey</li><li><a href="https://arxiv.org/abs/1705.02801" target="_blank" rel="noopener">[arxiv]</a> <a href="https://github.com/palash1992/GEM" target="_blank" rel="noopener">[Python]</a></li></ul></li><li><strong>DNE-SBP</strong><ul><li>Deep Network Embedding for Graph Representation Learning in Signed Networks</li><li><a href="https://ieeexplore.ieee.org/document/8486671" target="_blank" rel="noopener">[paper]</a> <a href="https://github.com/shenxiaocam/Deep-network-embedding-for-graph-representation-learning-in-signed-networks" target="_blank" rel="noopener">[Code]</a></li></ul></li></ul><h2 id="Paper-References"><a href="#Paper-References" class="headerlink" title="Paper References"></a>Paper References</h2><p><a href="https://arxiv.org/abs/1901.00596" target="_blank" rel="noopener">A Comprehensive Survey on Graph Neural Networks</a>, arxiv’19</p><p><a href="https://arxiv.org/pdf/1806.08804.pdf" target="_blank" rel="noopener">Hierarchical Graph Representation Learning with Differentiable Pooling</a>, NIPS’18</p><p><strong>SEMAC</strong>, <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16442" target="_blank" rel="noopener">Link Prediction via Subgraph Embedding-Based Convex Matrix Completion</a>, AAAI 2018, <a href="https://www.slideshare.net/gdm3003/semac-graph-node-embeddings-for-link-prediction" target="_blank" rel="noopener">Slides</a></p><p><strong>MILE</strong>, <a href="https://arxiv.org/pdf/1802.09612.pdf" target="_blank" rel="noopener">MILE: A Multi-Level Framework for Scalable Graph Embedding</a>, arxiv’18</p><p><strong>MetaGraph2Vec</strong>, <a href="https://arxiv.org/abs/1803.02533" target="_blank" rel="noopener">MetaGraph2Vec: Complex Semantic Path Augmented Heterogeneous Network Embedding</a></p><p><strong>PinSAGE</strong>, <a href="https://arxiv.org/abs/1806.01973" target="_blank" rel="noopener">Graph Convolutional Neural Networks for Web-Scale Recommender Systems</a></p><p><a href="https://dl.acm.org/citation.cfm?id=3159711" target="_blank" rel="noopener">Curriculum Learning for Heterogeneous Star Network Embedding via Deep Reinforcement Learning</a>, WSDM ‘18</p><p><a href="https://arxiv.org/abs/1711.07838" target="_blank" rel="noopener">Adversarial Network Embedding</a>, arxiv</p><p><strong>Role2Vec</strong>, <a href="https://arxiv.org/abs/1802.02896" target="_blank" rel="noopener">Learning Role-based Graph Embeddings</a></p><p><strong>edge2vec</strong>, <a href="https://arxiv.org/abs/1804.06111" target="_blank" rel="noopener">Feature Propagation on Graph: A New Perspective to Graph Representation<br>Learning</a></p><p><strong>MINES</strong>, <a href="http://cse.msu.edu/~mayao4/downloads/Multidimensional_Network_Embedding_with_Hierarchical_Structure.pdf" target="_blank" rel="noopener">Multi-Dimensional Network Embedding with Hierarchical Structure</a></p><p><a href="https://arxiv.org/abs/1804.05837" target="_blank" rel="noopener">Walk-Steered Convolution for Graph Classification</a></p><p><a href="https://arxiv.org/abs/1704.08829" target="_blank" rel="noopener">Deep Feature Learning for Graphs</a>, arxiv’17</p><p><a href="https://arxiv.org/abs/1710.10881" target="_blank" rel="noopener">Fast Linear Model for Knowledge Graph Embeddings</a>, arxiv’17</p><p><a href="https://arxiv.org/abs/1710.02971" target="_blank" rel="noopener">Network Embedding as Matrix Factorization: Unifying DeepWalk, LINE, PTE, and node2vec</a>, arxiv’17</p><p><a href="https://arxiv.org/abs/1709.07604" target="_blank" rel="noopener">A Comprehensive Survey of Graph Embedding: Problems, Techniques and Applications</a>, arxiv’17</p><p><a href="https://arxiv.org/pdf/1709.05584.pdf" target="_blank" rel="noopener">Representation Learning on Graphs: Methods and Applications</a>, IEEE DEB’17</p><p><strong>CONE</strong>, <a href="https://arxiv.org/abs/1709.01554" target="_blank" rel="noopener">CONE: Community Oriented Network Embedding</a>, arxiv’17</p><p><strong>LANE</strong>,<br><a href="http://dl.acm.org/citation.cfm?id=3018667" target="_blank" rel="noopener">Label Informed Attributed Network Embedding</a>, WSDM’17</p><p><strong>Graph2Gauss</strong>,<br><a href="https://arxiv.org/abs/1707.03815" target="_blank" rel="noopener">Deep Gaussian Embedding of Attributed Graphs: Unsupervised Inductive Learning via Ranking</a>, arxiv<br><a href="https://twitter.com/abojchevski/status/885502050133585925" target="_blank" rel="noopener">[Bonus Animation]</a></p><p><a href="https://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14696" target="_blank" rel="noopener">Scalable Graph Embedding for Asymmetric Proximity</a>, AAAI’17</p><p><a href="http://dl.acm.org/citation.cfm?id=2959169" target="_blank" rel="noopener">Query-based Music Recommendations via Preference Embedding</a>, RecSys’16</p><p><a href="http://dl.acm.org/citation.cfm?id=3060886" target="_blank" rel="noopener">Tri-party deep network representation</a>, IJCAI’16</p><p><a href="http://dl.acm.org/citation.cfm?id=2783296" target="_blank" rel="noopener">Heterogeneous Network Embedding via Deep Architectures</a>, KDD’15</p><p><a href="http://dl.acm.org/citation.cfm?id=2969070" target="_blank" rel="noopener">Neural Word Embedding As Implicit Matrix Factorization</a>, NIPS’14</p><p><a href="http://dl.acm.org/citation.cfm?id=2488393" target="_blank" rel="noopener">Distributed large-scale natural graph factorization</a>, WWW’13</p><p><a href="https://arxiv.org/abs/1610.09950" target="_blank" rel="noopener">From Node Embedding To Community Embedding</a>, arxiv</p><p><a href="https://arxiv.org/abs/1605.02115" target="_blank" rel="noopener">Walklets: Multiscale Graph Embeddings for Interpretable Network Classification</a>, arxiv</p><p><a href="https://arxiv.org/abs/1501.00358" target="_blank" rel="noopener">Comprehend DeepWalk as Matrix Factorization</a>, arxiv</p><h1 id="Conference-amp-Workshop"><a href="#Conference-amp-Workshop" class="headerlink" title="Conference &amp; Workshop"></a>Conference &amp; Workshop</h1><p><a href="http://www.mlgworkshop.org/2017/" target="_blank" rel="noopener">13th International Workshop on Mining and Learning with Graphs</a>, <strong>MLG’17</strong></p><p><a href="http://snap.stanford.edu/proj/embeddings-www/" target="_blank" rel="noopener">WWW-18 Tutorial Representation Learning on Networks</a>, <strong>WWW’18</strong></p><h2 id="Related-List"><a href="#Related-List" class="headerlink" title="Related List"></a>Related List</h2><p><a href="https://github.com/benedekrozemberczki/awesome-graph-classification" target="_blank" rel="noopener">awesome-graph-classification</a></p><p><a href="https://github.com/benedekrozemberczki/awesome-community-detection" target="_blank" rel="noopener">awesome-community-detection</a></p><p><a href="https://github.com/Hironsan/awesome-embedding-models" target="_blank" rel="noopener">awesome-embedding-models</a></p><p><a href="https://github.com/thunlp/NRLPapers" target="_blank" rel="noopener">Must-read papers on network representation learning (NRL) / network embedding (NE)</a></p><p><a href="https://github.com/thunlp/KRLPapers" target="_blank" rel="noopener">Must-read papers on knowledge representation learning (KRL) / knowledge embedding (KE)</a></p><p><a href="https://github.com/nate-russell/Network-Embedding-Resources" target="_blank" rel="noopener">Network Embedding Resources</a></p><p><a href="https://github.com/Hironsan/awesome-embedding-models" target="_blank" rel="noopener">awesome-embedding-models</a></p><p><a href="https://github.com/MaxwellRebo/awesome-2vec" target="_blank" rel="noopener">2vec-type embedding models</a></p><h2 id="Related-Project"><a href="#Related-Project" class="headerlink" title="Related Project"></a>Related Project</h2><p><strong>Stanford Network Analysis Project</strong> <a href="http://snap.stanford.edu/" target="_blank" rel="noopener">website</a></p><p><strong>StellarGraph Machine Learning Library</strong> <a href="https://www.stellargraph.io" target="_blank" rel="noopener">website</a> <a href="https://github.com/stellargraph/stellargraph" target="_blank" rel="noopener">GitHub</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Graph Embeddings </category>
          
      </categories>
      
      
        <tags>
            
            <tag> papers </tag>
            
            <tag> graph embedding </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git开发相关操作记录</title>
      <link href="/2019/11/16/git-notes/"/>
      <url>/2019/11/16/git-notes/</url>
      
        <content type="html"><![CDATA[<h2 id="如何对开源项目贡献代码"><a href="#如何对开源项目贡献代码" class="headerlink" title="如何对开源项目贡献代码"></a>如何对开源项目贡献代码</h2><ol><li>Fork开源项目</li><li>将开源项目下载到自己的电脑(git clone xxx)</li><li>创建自己的分支(git checkout -b my-new-branch)</li><li>修改后添加修改(git add .)</li><li>提交修改，并写好描述(git commit -m ‘xxx’)</li><li>提交修改到分支(git push origin my-new-branch)</li><li>发起新的reqeust</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Git </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JDK自带工具详解汇总</title>
      <link href="/2019/11/14/java-jvm-4/"/>
      <url>/2019/11/14/java-jvm-4/</url>
      
        <content type="html"><![CDATA[<h1 id="深入理解Java虚拟机读书笔记-3-JDK自带工具详解汇总（不断更新）"><a href="#深入理解Java虚拟机读书笔记-3-JDK自带工具详解汇总（不断更新）" class="headerlink" title="深入理解Java虚拟机读书笔记(3): JDK自带工具详解汇总（不断更新）"></a>深入理解Java虚拟机读书笔记(3): JDK自带工具详解汇总（不断更新）</h1><p>对于初学者来说，学习Java时可能仅仅认识了<code>java</code>和<code>javac</code>两个命令，其他的命令没有基础过。其实jdk自带了非常多的非常好用的工具，在windows环境下，打开jdk下的bin目录，可以看到很多exe文件，如下图所示：</p><p><img src="C:%5CUsers%5Ctenyun%5CDesktop%5C%E6%89%BE%E5%B7%A5%E4%BD%9C%5C%E7%AC%94%E8%AE%B0%5Cimgs%5C1546841202292.png" alt="1546841202292"></p><p>同样的，在linux环境下jdk的bin目录下也一样提供了很多工具，这些是编译好的二进制可执行脚本：</p><p><img src="C:%5CUsers%5Ctenyun%5CDesktop%5C%E6%89%BE%E5%B7%A5%E4%BD%9C%5C%E7%AC%94%E8%AE%B0%5Cimgs%5C1546841337590.png" alt="1546841337590"></p><p>下面就比较常用的一些工具做具体介绍。</p><blockquote><p>做介绍之前，提供一个官方的文档，所有命令的用法介绍、参数详解、结果详解都可以查询到</p><p>地址为：<a href="https://docs.oracle.com/javase/8/docs/technotes/tools/unix/index.html" target="_blank" rel="noopener">https://docs.oracle.com/javase/8/docs/technotes/tools/unix/index.html</a></p><p>此为JDK1.8的，其他版本自己对应查找连接即可。</p><p>下面介绍的时候也是按照官方文档的分类方法。</p></blockquote><h2 id="监控JVM的命令"><a href="#监控JVM的命令" class="headerlink" title="监控JVM的命令"></a>监控JVM的命令</h2><h3 id="一、jps"><a href="#一、jps" class="headerlink" title="一、jps"></a>一、jps</h3><p>对于搞大数据的人来说，jps命令可以说是最常用的命令之一了，它可以用来查看当前运行的虚拟机进程。<a href="https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jps.html#CHDCGECD" target="_blank" rel="noopener">官方文档地址</a></p><p>使用方法为<code>jps [option] [hostid]</code></p><p>参数介绍：</p><p>-q  仅输出VM标识符，不包括class name,jar name,arguments in main method，也就是仅输出进程ID了<br>-m 输出main method的参数<br>-l   输出完全的包名，应用主类名，jar的完全路径名<br>-v  输出jvm参数<br>-V 输出通过flag文件传递到JVM中的参数.hotspotrc文件或-XX:Flags=所指定的文件<br>-Joption 传递参数到vm,例如:-J-Xms48m</p><p>hostid一般是本地java进行id，也可以是远程的，格式如下</p><p><code>[protocol:][[//]hostname][:port][/servername]</code></p><p><strong>如果需要查看其他机器上的jvm进程，需要在待查看机器上启动jstatd。</strong></p><p> 命令的输出格式 ：<br>lvmid [ [ classname| JARfilename | “Unknown”][ arg* ] [ jvmarg* ] ]</p><p>几种使用情况介绍：</p><p>1） 无任何参数，直接jps，此时默认输出所有jvm进程，并打印ID和主类名</p><p><img src="C:%5CUsers%5Ctenyun%5CDesktop%5C%E6%89%BE%E5%B7%A5%E4%BD%9C%5C%E7%AC%94%E8%AE%B0%5Cimgs%5C1546842679601.png" alt="1546842679601"></p><p>2） jps -q 仅显示进程id</p><p><img src="C:%5CUsers%5Ctenyun%5CDesktop%5C%E6%89%BE%E5%B7%A5%E4%BD%9C%5C%E7%AC%94%E8%AE%B0%5Cimgs%5C1546842700335.png" alt="1546842700335"></p><p>3） jps -l 输出完全的包名，主类名，jar完全路径名</p><p><img src="C:%5CUsers%5Ctenyun%5CDesktop%5C%E6%89%BE%E5%B7%A5%E4%BD%9C%5C%E7%AC%94%E8%AE%B0%5Cimgs%5C1546842734126.png" alt="1546842734126"></p><p>4） jps -v 显示jvm参数</p><p><img src="C:%5CUsers%5Ctenyun%5CDesktop%5C%E6%89%BE%E5%B7%A5%E4%BD%9C%5C%E7%AC%94%E8%AE%B0%5Cimgs%5C1546842772451.png" alt="1546842772451"></p><p>jps用法简单，使用频率非常高。</p><h3 id="二、jstat"><a href="#二、jstat" class="headerlink" title="二、jstat"></a>二、jstat</h3><p>这个命令用于分析某个jvm进程的jvm的使用情况的统计信息，它可以显示本地或者远程[1]虚拟机进程中的类装载、 内存、 垃圾收集、 JIT编译等运行数据，在没有GUI图形界面，只提供了纯文本控制台环境的服务器上，它将是运行期定位虚拟机性能问题的首选工具。 命令格式为：</p><p><code>jstat [ generalOption | outputOptions vmid [ interval[s|ms] [ count ] ]</code></p><p>具体介绍：</p><p>generalOption：其实就是-h或者-options</p><p>outputOptions：由单个statOption或加上其他-t、-h和-J组成的options，用于确定输出的内容和格式</p><p>输出是表格的形式，表头字段用于描述列内容。-h设置表头的打印频率，例如-h3用于表示每3行打印一次表头部。使用-t选项显示时间戳列，标记为Timestamp作为输出的第一列。Timestamp列包含自目标JVM启动以来经过的时间（以秒为单位）。时间戳的分辨率取决于各种因素，并且由于在高负载系统上延迟的线程调度而受到变化。</p><p>vmid: Virtual machine identifier的缩写，一般就是本地进程ID或者是远程服务器进程</p><p>interval[s|ms]： 秒或者毫秒，即多少秒/毫秒打印一次，默认为毫秒</p><p>count: 一共打印多少次</p><p>官方不建议编写脚本来解析jstat命令的输出，因为格式会在不同版本中更改。</p><p>一些-<em>statOption</em>：</p><table><thead><tr><th>参数名称</th><th>参数作用</th></tr></thead><tbody><tr><td>class</td><td>显示有关类加载方面的统计信息</td></tr><tr><td>compiler</td><td>显示有关Java HotSpot VM实时编译器行为的统计信息</td></tr><tr><td>gc</td><td>显示有关垃圾回收堆行为的统计信息</td></tr><tr><td>gccapacity</td><td>显示有关代的容量及其相应空间的统计信息</td></tr><tr><td>gccause</td><td>显示有关垃圾收集统计信息（与-gcutil相同）的摘要，其中包含最后一个和当前垃圾收集事件的原因</td></tr><tr><td>gcnew</td><td>显示年轻代行为的统计信息</td></tr><tr><td>gcnewcapacity</td><td>显示有关年轻代及其相应空间大小的统计信息</td></tr><tr><td>gcold</td><td>显示有关老年代和元数据空间统计信息行为的统计信息</td></tr><tr><td>gcoldcapacity</td><td>显示有关老年代大小的统计信息</td></tr><tr><td>gcmetacapacity</td><td>显示有关元数据空间大小的统计信息</td></tr><tr><td>gcutil</td><td>显示有关垃圾收集统计信息的摘要</td></tr><tr><td>printcompilation</td><td>显示Java HotSpot VM编译方法统计信息</td></tr></tbody></table><p>举例如下：</p><p>如下表示分析进程id为31736 的gc情况，每隔1000ms打印一次记录，打印10次停止，每3行后打印指标头部</p><pre class=" language-bash"><code class="language-bash">jstat -gc -h3 11919 1000 10</code></pre><p>结果如下所示：</p><p><img src="C:%5CUsers%5Ctenyun%5CDesktop%5C%E6%89%BE%E5%B7%A5%E4%BD%9C%5C%E7%AC%94%E8%AE%B0%5Cimgs%5C1546849787600.png" alt="1546849787600"></p><p>结果指标含义如下：</p><table><thead><tr><th align="center">参数</th><th align="center">描述</th></tr></thead><tbody><tr><td align="center">S0C</td><td align="center">年轻代中第一个survivor（幸存区）的容量 (字节)</td></tr><tr><td align="center">S1C</td><td align="center">年轻代中第二个survivor（幸存区）的容量 (字节)</td></tr><tr><td align="center">S0U</td><td align="center">年轻代中第一个survivor（幸存区）目前已使用空间 (字节)</td></tr><tr><td align="center">S1U</td><td align="center">年轻代中第二个survivor（幸存区）目前已使用空间 (字节)</td></tr><tr><td align="center">EC</td><td align="center">年轻代中Eden（伊甸园）的容量 (字节)</td></tr><tr><td align="center">EU</td><td align="center">年轻代中Eden（伊甸园）目前已使用空间 (字节)</td></tr><tr><td align="center">OC</td><td align="center">老年代的容量 (字节)</td></tr><tr><td align="center">OU</td><td align="center">老年代目前已使用空间 (字节)</td></tr><tr><td align="center">PC</td><td align="center">Perm(持久代)的容量 (字节)</td></tr><tr><td align="center">PU</td><td align="center">Perm(持久代)目前已使用空间 (字节)</td></tr><tr><td align="center">YGC</td><td align="center">从应用程序启动到采样时年轻代中gc次数</td></tr><tr><td align="center">YGCT</td><td align="center">从应用程序启动到采样时年轻代中gc所用时间(s)</td></tr><tr><td align="center">FGC</td><td align="center">从应用程序启动到采样时老年代(全gc)gc次数</td></tr><tr><td align="center">FGCT</td><td align="center">从应用程序启动到采样时老年代(全gc)gc所用时间(s)</td></tr><tr><td align="center">GCT</td><td align="center">从应用程序启动到采样时gc用的总时间(s）</td></tr></tbody></table><p>其他命令统计结果可以<a href="https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jstat.html#BEHHGFAE" target="_blank" rel="noopener">查阅文档</a>， 一般都是生产环境下不方面使用其他工具的时候使用此命令大致查看gc信息。</p><h3 id="三、jstatd"><a href="#三、jstatd" class="headerlink" title="三、jstatd"></a>三、jstatd</h3><p>这是一个远程调用服务程序，监视Java虚拟机（JVM）并使远程监视工具能够连接到JVM。比如jps、jinfo等对远程服务器使用，那么远程服务器上就要启动jstatd才可以。</p><p>用法：</p><p><code>jstatd [options]</code></p><p>参数命令：</p><p>-nr : 当找不到现有的RMI注册表时，不会尝试在jstatd进程中创建内部RMI注册表。</p><p>-p port ： 如果未指定-nr选项，则在创建RMI注册表或未找到RMI注册表时创建的端口号。</p><p>-n rminame： 远程RMI对象在RMI注册表中绑定到的名称，默认名称为JStatRemoteHost。如果一个服务器上启动了多个jstatd服务，可以使用此参数为不同的jstatd服务指定唯一标识。</p><p>-Joption: 传递JVM的参数，其中option是Java应用程序启动器参数。例如，-J-Xms48m将启动内存设置为48 MB</p><h2 id="故障排除命令"><a href="#故障排除命令" class="headerlink" title="故障排除命令"></a>故障排除命令</h2><h3 id="一、jinfo"><a href="#一、jinfo" class="headerlink" title="一、jinfo"></a>一、jinfo</h3><p>jinfo 是jdk自带的一个工具，它可以用来查看<code>正在运行的java应用程序的扩展参数</code>（JVM中-X、-XX标示的参数），甚至支持在运行时修改部分参数。配置信息包括Java系统属性和Java虚拟机（JVM）命令行参数。对于64位JVM，可以加一个可选参数 <code>-J-d64</code>，例如<code>jinfo</code> <code>-J-d64 -sysprops pid</code>.</p><p><a href="https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jinfo.html#BCGEBFDD" target="_blank" rel="noopener">官方文档地址</a></p><p>用法如下：</p><p><code>jinfo [option] &lt;pid&gt;</code> 用于连接正在运行的进程</p><p><code>jinfo [option] &lt;executable &lt;core&gt;</code> 用于连接一个核文件</p><p><code>jinfo [option][server_id@]&lt;remote server IP or hostname&gt;</code> 用于连接一个远程debug服务器</p><p>option参数如下：</p><p>-flag <name>          打印指定的name参数的名称和值<br>-flag [+|-]<name>    使用或取消名称为name的Boolean参数<br>-flag <name>=<value> 设置name参数为给定value<br>-flags                       打印所有传递给JVM的命令行参数<br>-sysprops                打印Java系统属性<br><no option="">        打印上面所有内容<br>-h | -help                 打印帮助信息</no></value></name></name></name></p><p>1） jinfo -flags pid</p><p><img src="C:%5CUsers%5Ctenyun%5CDesktop%5C%E6%89%BE%E5%B7%A5%E4%BD%9C%5C%E7%AC%94%E8%AE%B0%5Cimgs%5C1546844867487.png" alt="1546844867487"></p><p>2） jinfo -flag -XX:CICompilerCount pid  查看某个具体的参数的值</p><p><img src="C:%5CUsers%5Ctenyun%5CDesktop%5C%E6%89%BE%E5%B7%A5%E4%BD%9C%5C%E7%AC%94%E8%AE%B0%5Cimgs%5C1546845113000.png" alt="1546845113000"></p><h3 id="二、jmap"><a href="#二、jmap" class="headerlink" title="二、jmap"></a>二、jmap</h3><p>jmap（Memory Map for Java）命令用于生成堆转储快照（一般称为heapdump或dump文件） ，此文件是分析应用程序可能发生的问题以及调优的重要文件。jmap的作用并不仅仅是为了获取dump文件，它还可以查询finalize执行队列、 Java堆和永久代的详细信息，如空间使用率、 当前用的是哪种收集器等 。</p><p>命令格式：</p><p><strong>jmap</strong> [ <em>options</em> ] <em>pid</em></p><p>option可选值介绍如下：</p><table><thead><tr><th align="center">参数</th><th align="center">含义</th></tr></thead><tbody><tr><td align="center">-dump</td><td align="center">生成java堆转储快照。格式为：-dump:[live,] format=b, file=<em>filename</em>，live参数作用是控制是否只dump出存活的对象，存储文件为hporf二进制文件。可以配合jhap命令浏览分析转储出的文件。</td></tr><tr><td align="center">-finalizerinfo</td><td align="center">显示在F-Queue中等待Finalizer线程执行finalize方法的对象。只在Linux/Solaris平台下有效。</td></tr><tr><td align="center">-heap</td><td align="center">显示Java堆中的详细信息，包括使用哪种收集器、参数配置、分代状况等，只在Linux/Solaris平台下有效。</td></tr><tr><td align="center">-histo</td><td align="center">显示堆中对象统计信息，包括类、实例数量、合计容量</td></tr><tr><td align="center">-permstat</td><td align="center">以ClassLoader为统计口径显示永久代内存状态。只在Linux/Solaris平台下有效。</td></tr><tr><td align="center">-F</td><td align="center">当虚拟机进程堆-dum参数没有响应时，可以使用这个选项强制生成dump快照。只在Linux/Solaris平台下有效。</td></tr><tr><td align="center">-clstats</td><td align="center">显示Java堆的类加载器的统计信息。对于每个类加载器，它的名称，活动程度，地址，父类加载器以及它加载的类的数量和大小都会被打印出来。</td></tr></tbody></table><h3 id="三、jhat"><a href="#三、jhat" class="headerlink" title="三、jhat"></a>三、jhat</h3><p>jhat（Java Heap Analysis Tool）一般与jmap搭配使用，用途分析jmap生成的堆转储快照。jhap内置一个http服务器，可以在浏览器中查看分析结果。但是这个工具分析结果比较简陋，而且一般不会直接在服务器上直接分析dump文件，所以比较鸡肋。有很多其他优秀的分析工具可以使用，比如VisualVM、MAT等，后面会介绍。</p><p>命令格式：</p><p>jhat filename</p><h2 id="可视化监控与分析Java应用程序"><a href="#可视化监控与分析Java应用程序" class="headerlink" title="可视化监控与分析Java应用程序"></a>可视化监控与分析Java应用程序</h2><h3 id="一、JConsole"><a href="#一、JConsole" class="headerlink" title="一、JConsole"></a>一、JConsole</h3><p>jconsole命令启动图形控制台工具，可以监视和管理本地或远程计算机上的Java应用程序和虚拟机。它基于JMX技术，它管理部分的功能是针对JMX MBean进行管理，MBean可以使用代码、 中间件服务器的管理控制台或者所有符合JMX规范的软件进行访问。</p><p>在Windows下，启动在jdk/bin 下的jconsole.exe以后将自动搜索出本机运行的所有虚拟机进程，不需要通过jps来查询，然后选择一个进程即可开始监控。如下图所示：</p><p><img src="C:%5CUsers%5Ctenyun%5CDesktop%5C%E6%89%BE%E5%B7%A5%E4%BD%9C%5C%E7%AC%94%E8%AE%B0%5Cimgs%5C1547118823186.png" alt="1547118823186"></p><p>jconsole包含了非常丰富的信息，主界面如下图所示：</p><p><img src="C:%5CUsers%5Ctenyun%5CDesktop%5C%E6%89%BE%E5%B7%A5%E4%BD%9C%5C%E7%AC%94%E8%AE%B0%5Cimgs%5C1547119121812.png" alt="1547119121812"></p><p>可以看到，可以查看概述、内存、线程、类、vm概要、MBean等六大类信息，每一类下面都包括丰富的图标和文字统计信息，非常强大。 </p><p>“概述”页签显示的是整个虚拟机主要运行数据的概览，其中包括“堆内存使用情况”、“线程”、 “类”、 “CPU使用情况”4种信息的曲线图。</p><p>“内存”页签相当<code>于可视化的jstat命令</code>，用于监视受收集器管理的虚拟机内存（Java堆和永久代）的变化趋势。  </p><p>“线程”页签的功能相当于可视化的jstack命令，遇到线程停顿时可以使用这个页签进行监控分析。</p><p> “VM概要”里面则显示了虚拟机的信息，如下图所示：</p><p><img src="C:%5CUsers%5Ctenyun%5CDesktop%5C%E6%89%BE%E5%B7%A5%E4%BD%9C%5C%E7%AC%94%E8%AE%B0%5Cimgs%5C1547120203637.png" alt="1547120203637"></p><h3 id="二、-VisualVM"><a href="#二、-VisualVM" class="headerlink" title="二、 VisualVM"></a>二、 VisualVM</h3><p>VisualVM（All-in-One Java Troubleshooting Tool） 是到目前为止随JDK发布的功能最强大的<code>运行监视</code>和<code>故障处理</code>程序 ，它不仅可以用来运行监视、故障处理，还可以用来进行<code>性能分析</code>。</p><p>它还支持<code>插件拓展</code>。结合插件，VisualVM可以做到很多强大的功能，比如：</p><ul><li>显示虚拟机进程以及进程的配置、 环境信息（jps、 jinfo） </li><li>监视应用程序的CPU、 GC、 堆、 方法区以及线程的信息（jstat、 jstack） </li><li>dump以及分析堆转储快照（jmap、 jhat） </li><li>方法级的程序运行性能分析，找出被调用最多、 运行时间最长的方法 </li><li>离线程序快照：收集程序的运行时配置、 线程dump、 内存dump等信息建立一个快照，可以将快照发送开发者处进行Bug反馈 </li><li>……</li></ul><p>其程序主界面如下图所示：</p><p><img src="C:%5CUsers%5Ctenyun%5CDesktop%5C%E6%89%BE%E5%B7%A5%E4%BD%9C%5C%E7%AC%94%E8%AE%B0%5Cimgs%5C1547127396252.png" alt="1547127396252"></p><p>选择本地某个进程点进去，发现其主要功能和JConsole差不多，但是其支持插件，所以有更多强大的功能，而且可视化界面更加友好。在监视选项卡下支持堆dump，点击之后会生成堆dump文件，并自动加载分析，得到分析结果，如下所示：</p><p><img src="C:%5CUsers%5Ctenyun%5CDesktop%5C%E6%89%BE%E5%B7%A5%E4%BD%9C%5C%E7%AC%94%E8%AE%B0%5Cimgs%5C1547127653210.png" alt="1547127653210"></p><p>当VisualVM关闭时，此dump文件会自动删除，所以如果想要保存，需要在选项卡上右击另存为。</p><p>VisualVM还支持分析程序性能的功能。在Profiler页签中，VisualVM提供了程序运行期间方法级的CPU执行时间分析以及内存分析，做Profiling分析肯定会对程序运行性能有比较大的影响，所以一般不在生产环境中使用这项功能。 选择“CPU”和“内存”按钮中的一个，然后切换到应用程序中对程序进行操作，VisualVM会记录到这段时间中应用程序执行过的方法。 比如如果是CPU分析，将会统计每个方法的执行次数、 执行耗时；如果是内存分析，则会统计每个方法关联的对象数以及这些对象所占的空间。  </p><p>VisualVM有两个很重要的插件，<code>VisualGC</code>和<code>BTrace动态日志跟踪</code>。</p><p>VisualGC对进程的GC情况作了统计和可视化，效果如下所示：</p><p><img src="C:%5CUsers%5Ctenyun%5CDesktop%5C%E6%89%BE%E5%B7%A5%E4%BD%9C%5C%E7%AC%94%E8%AE%B0%5Cimgs%5C1547127922111.png" alt="1547127922111"></p><p>BTrace的作用是在不停止目标程序运行的前提下，通过HotSpot虚拟机的HotSwap技术[4]动态加入原本并不存在的调试代码。  这项功能对实际生产中的程序很有意义：经常遇到程序出现问题，但排查错误的一些必要信息，譬如方法参数、 返回值等，在开发时并没有打印到日志之中，以至于不得不停掉服务，通过调试增量来加入日志代码以解决问题。 当遇到生产环境服务无法随便停止时，缺一两句日志导致排错进行不下去是一件非常郁闷的事情。</p><p>BTrace脚本编写和Java很像，但也有很多东西需要学，这里暂时不多做介绍。 </p><p>至于插件的安装，非常简单，在菜单栏的工具-&gt;插件点击即可，如下图所示：</p><p><img src="C:%5CUsers%5Ctenyun%5CDesktop%5C%E6%89%BE%E5%B7%A5%E4%BD%9C%5C%E7%AC%94%E8%AE%B0%5Cimgs%5C1547128104143.png" alt="1547128104143"></p><p>选择想要安装的插件点击安装即可自动下载安装，也可以去VisualVM官网去下载插件然后放到指定的位置，这里不多做介绍，有兴趣的可以自己查阅资料。[插件官方地址](<a href="http://Visualvm" target="_blank" rel="noopener">http://Visualvm</a> java.net/pluginscenters.html )</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> JVM </tag>
            
            <tag> JDK </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JVM参数类型分类</title>
      <link href="/2019/11/14/java-jvm-3/"/>
      <url>/2019/11/14/java-jvm-3/</url>
      
        <content type="html"><![CDATA[<h1 id="深入理解Java虚拟机读书笔记-3-JVM参数类型分类"><a href="#深入理解Java虚拟机读书笔记-3-JVM参数类型分类" class="headerlink" title="深入理解Java虚拟机读书笔记(3): JVM参数类型分类"></a>深入理解Java虚拟机读书笔记(3): JVM参数类型分类</h1><p>JVM有很多参数，一般可以分为三大类：标准参数、X参数和XX参数</p><h2 id="标准参数"><a href="#标准参数" class="headerlink" title="标准参数"></a>标准参数</h2><p>所谓标准参数，即一般化参数，往往是固定不变的，比如以下参数：</p><ul><li><p>-help</p></li><li><p>-version 显式虚拟机类型 当前版本号等等<br>这里注意JVM默认开启了mixmode混合模式，这意味着JVM在运行时可以动态的把字节码编译成本地代码</p></li><li><p>-server、-client</p><p>-server  默认为堆提供了一个更大的空间和并行的垃圾收集器，并且在运行时可以更大程度的优化代码</p><p>-client   客户端虚拟机有较小的默认堆内存，可以缩短JVM启动的时间和占用更少的内存，客户端的JVM只有在32位操作系统中才有</p><blockquote><p>注意</p></blockquote><p>1 ) 从JDK5开始 当应用启动时会检测当前的运行环境是否是服务器 如果是服务器就使用Server JVM 这是为了提升性能，一般来说Server JVM启动比Client JVM慢，原因是使用的是重量级的虚拟机，但是内部进行了很多优化，而Client JVM使用的是轻量级的JVM，当服务稳定运行后还是Server JVM的速度更快一些<br>2 ) 在JDK6中 Server JVM要求至少双核CPU和2GB物理内存</p><p>3 ) 在32位操作系统上 JDK可以运行Server JVM 但是JRE只能运行Client JVM</p></li><li><p>-cp、-classpath</p></li></ul><h2 id="X参数"><a href="#X参数" class="headerlink" title="X参数"></a>X参数</h2><p>X参数是非标准化参数，在java的各个jdk版本中可能会发生微小的变化，比如如下几个常用的：</p><ul><li>-Xlint：解释执行, int是interpretation的简称，翻译解释的意思，意味着强制JVM执行所有的字节码，这会降低运行速度[10倍左右]</li><li>-Xcomp：comp是Compile的简称，编译的意思第一次使用就编译成本地代码，从而带来最大程度的优化，虽然比-Xint的效率要高，但是它<code>没有让JVM启动JIT编译器的全部功能</code>， JIT编译器一般会在运行时创建方法使用文件，然后一步步的优化每个方法，因此该指令还是会造成一定的效率衰减</li><li>-Xmixed：混合模式，JVM自己来决定是否编译成本地代码，默认开启了混合模式，因此无需显式的指定</li></ul><p>Java是解释执行的，但是虚拟机里JIT即时编译的部分，可以把java代码转换成本地代码，上面的参数就是控制编译本地代码的参数。</p><h2 id="XX参数"><a href="#XX参数" class="headerlink" title="XX参数"></a>XX参数</h2><p>XX参数也是一种非标准化的参数，用户可以自己设置，JVM调优和debug都是用这些参数，主要分为以下两大类：</p><ul><li>Boolean类型</li></ul><p>格式：-XX:[+-]<name>方括号里面的+-表示启用或者禁用name属性</name></p><p>比如：-XX:+UseConcMarkSweepGC 表示穷CMS垃圾收集器 </p><p>​    -XX:+UseG1GC等</p><ul><li>非Boolean类型</li></ul><p>此类型一般是key-value类型</p><p>格式：-XX:<name>=<value>表示name属性的值是value</value></name></p><p>比如：XX:MaxGCPauseMillis=500 设置GC收集暂停时间为500</p><h2 id="特例"><a href="#特例" class="headerlink" title="特例"></a>特例</h2><p>还有一些非常常用的参数，比如-Xmx -Xms等，看个以为是X参数，其实是XX参数</p><p>-Xms 等价于 -XX:InitialHeapSize  初始化的堆大小</p><p>-Xmx 等价于 -XX:MaxHeapSize    最大化的堆大小</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>JVM参数非常多，但一般使用的是XX参数居多，用于调优和debug错误。具体使用哪些参数，需要具体问题具体分析，目前jdk自带的虚拟机实现都是HotSpot，可以查阅相关文档。</p><p>也可以下载某个知名论坛整理的文档，<a href="http://disq.us/url?url=http%3A%2F%2Ffiles.zeroturnaround.com%2Fpdf%2Fzt_JVM-options-cheat-sheet.pdf%3AsfOsGCixViJ6_yNr5059YY8qq7g&amp;cuid=344030" target="_blank" rel="noopener">下载地址</a></p><p><img src="https://zeroturnaround.com/wp-content/uploads/2016/12/JVM-Options-cheat-sheet-v2.png" alt="img"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入理解HotSpot虚拟机对象</title>
      <link href="/2019/11/14/java-jvm-2/"/>
      <url>/2019/11/14/java-jvm-2/</url>
      
        <content type="html"><![CDATA[<h1 id="深入理解Java虚拟机读书笔记-2-深入理解HotSpot虚拟机对象"><a href="#深入理解Java虚拟机读书笔记-2-深入理解HotSpot虚拟机对象" class="headerlink" title="深入理解Java虚拟机读书笔记(2): 深入理解HotSpot虚拟机对象"></a>深入理解Java虚拟机读书笔记(2): 深入理解HotSpot虚拟机对象</h1><p>为了理解虚拟机中数据的细节，比如如何创建、如何布局以及如何访问，必须具体到某一虚拟机和某一个内存区域。此处深入探讨HotSpot虚拟机在Java堆中对象分配、布局和访问的全过程。</p><h2 id="一、对象的创建"><a href="#一、对象的创建" class="headerlink" title="一、对象的创建"></a>一、对象的创建</h2><p>反映到Java语言中，对象的创建通常不过是一个<code>new</code>关键字，然而反映到底层虚拟机上是如何呢？可以概括为以下三步：</p><ul><li><p><strong>类加载：</strong> 虚拟机遇到一个new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个<code>类的符号引用</code>，并且检查这个符号引用代表的类<code>是否已被加载、 解析和初始化过</code>。 如果没有，那必须先执行相应的类加载过程。</p></li><li><p><strong>分配内存：</strong> 类加载通过后，虚拟机为新生对象分配内存。对象所需内存的大小在类加载完成后便可完全确定，为对象分配空间的任务等同于把一块确定大小的内存从Java堆中划分出来。 这里一般有两种划分方式：</p><ul><li>Java堆中内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是<code>把那个指针向空闲空间那边挪动一段与对象大小相等的距离</code>，这种分配方式称为<code>“指针碰撞”(Bump the Pointer)</code>。</li><li>Java堆中内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，<code>记录哪些内存块是可用的</code>，在分配的时候<code>从列表中找到一块足够大的空间划分给对象实例</code>，并更新列表上的记录，这种分配方式称为<code>“空闲列表”（Free List）</code>。 </li></ul><p>选择哪种分配方式<code>由Java堆是否规整决定</code>，而Java堆是否规整又由所采用的垃圾收集器<code>是否带有压缩整理功能决定</code>。 因此，在使用Serial、 ParNew等带Compact过程的收集器时，系统采用的分配算法是指针碰撞，而使用CMS这种基于Mark-Sweep算法的收集器时，通常采用空闲列表。 </p><p>在分配内存时，另外一个需要考虑的问题是线程安全性。对象创建时一个非常频繁的行为，即使是仅仅修改一个指针所指向的位置，在并发情况下也并不是线程安全的。例如可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存的情况。  针对此问题有两种解决方案：</p><ul><li>对分配内存空间的动作进行同步处理：即虚拟机采用CAS+失败重试的方式保证更新操作的原子性</li><li>把内存分配的动作按照线程划分在不同得空间中进行，即每个线程在Java堆中预先分配一小块内存，称为<code>本地线程分配缓冲（Thread Local Allocation Buffer,TLAB）</code> 。这有点类似于线程封闭技术，哪个线程要分配内存，就在哪个线程的TLAB上分配，只有TLAB用完并分配新的TLAB时，才需要同步锁定。虚拟机是否使用TLAB，可以通过-XX：+/-UseTLAB参数来设定。 </li></ul></li><li><p><strong>初始化：</strong> 内存分配完成后，需要对分配到的内存空间都进行初始化为<code>零值</code>（不包括对象头），如果使用TLAB，这一工作过程也可以提前至TLAB分配时进行。 这一步的动作，保证了对象的实例字段在Java代码中可以<code>不赋初值就可以直接使用</code>，程序能访问到这些字段的数据类型所对应的零值。 </p></li><li><p><strong>对象头设置</strong>：上面的初始化仅仅是通用的设置并且不包括对象头的设置，虚拟机接下来还要对对象进行更加丰富的设置，例如这个对象是哪个类的实例、 如何才能找到类的元数据信息、 对象的哈希码、 对象的GC分代年龄等信息。 这些信息存放在对象的<code>对象头（Object Header）</code>之中。 根据虚拟机当前的运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。 </p></li><li><p><strong>对象init：</strong> 完成上面的工作以后，在虚拟机中其实一个对象已经产生了，但是从Java代码来看，其实<init>方法还没有执行，此时所有的字段还停留在初始化时设置的零值。一般来说（由字节码中是否跟随invokespecial指令所决定），执行new指令之后会接着执行＜init＞方法，<code>把对象按照程序员的意愿进行初始化</code>，这样一个真正可用的对象才算完全产生出来。 </init></p></li></ul><p>至此，一个对象创建完成。那么，对象在内存中又是如何布局的呢？</p><h2 id="二、对象的内存布局"><a href="#二、对象的内存布局" class="headerlink" title="二、对象的内存布局"></a>二、对象的内存布局</h2><p>在HotSpot虚拟机中，对象在内存中存储的布局可以分为3块区域：<code>对象头（Header）、实例数据（Instance Data）</code>和<code>对齐填充（Padding）</code>。 </p><h3 id="2-1-对象头"><a href="#2-1-对象头" class="headerlink" title="2.1 对象头"></a>2.1 对象头</h3><p>对象头包括两部分信息，即对象运行时信息和类型指针。</p><p>第一部分用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、 锁状态标志、 线程持有的锁、 偏向线程ID、 偏向时间戳等，这部分数据的长度在32位和64位的虚拟机（未开启压缩指针）中分别为32bit和64bit，官方称它为<code>“Mark Word”</code>。  对象头信息是与对象自身定义的数据无关的额外存储成本，考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它会根据对象的状态复用自己的存储空间。  </p><p>对象头的另外一部分是类型指针，即<code>对象指向它的类元数据的指针</code>，虚拟机<code>通过这个指针来确定这个对象是哪个类的实例</code>。  并不是所有的虚拟机实现都必须在对象数据上保留类型指针，换句话说，<code>查找对象的元数据信息并不一定要经过对象本身。</code>另外，如果对象是一个Java数组，那在对象头中还必须有一块用于记录数组长度的数据，因为虚拟机可以通过普通Java对象的元数据信息确定Java对象的大小，但是<code>从数组的元数据中却无法确定数组的大小</code>。 </p><h3 id="2-2-实例数据"><a href="#2-2-实例数据" class="headerlink" title="2.2 实例数据"></a>2.2 实例数据</h3><p>实例数据部分是对象真正存储的有效信息，也是在程序代码中所定义的各种类型的字段内容，包括子类和父类的。关于存储顺序，受到虚拟机分配策略参数和字段在源码中定义顺序的影响。一般来说，相同宽度的字段总是被分配到一起，在此前提下，父类中定义的变量会出现在子类之前。如果CompactFields参数值为true（默认为true），那么子类之中较窄的变量也可能会插入到父类变量的空隙之中。 </p><h3 id="2-3-对齐填充"><a href="#2-3-对齐填充" class="headerlink" title="2.3 对齐填充"></a>2.3 对齐填充</h3><p>这一部分不是必然存在的，仅仅起着占位符的作用，没有什么实际含义。由于HotSpot VM的自动内存管理系统要求<code>对象起始地址必须是8字节的整数倍</code>，换句话说，就是<code>对象的大小必须是8字节的整数倍</code>。 而对象头部分正好是8字节的倍数（1倍或者2倍），因此，<code>当对象实例数据部分没有对齐时，就需要通过对齐填充来补全</code>。 </p><h2 id="三、对象的访问"><a href="#三、对象的访问" class="headerlink" title="三、对象的访问"></a>三、对象的访问</h2><p>Java程序通过<code>栈上的reference</code>数据来操作<code>堆上的具体对象</code>。由于reference类型在Java虚拟机规范中只规定了一个指向对象的引用，并没有定义这个引用应该通过何种方式去定位、 访问堆中的对象的具体位置，所以对象访问方式也是取决于虚拟机实现而定的。 目前主流的访问方式有使用<code>句柄</code>和<code>直接指针</code>两种。 关于句柄，可以参考知乎的这个话题<a href="https://www.zhihu.com/question/27656256/answer/37556901" target="_blank" rel="noopener">句柄是什么？</a></p><h3 id="句柄访问"><a href="#句柄访问" class="headerlink" title="句柄访问"></a>句柄访问</h3><p>如果使用句柄访问，Java堆中会划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。如下图所示：</p><p><img src="C:%5CUsers%5Ctenyun%5CDesktop%5C%E6%89%BE%E5%B7%A5%E4%BD%9C%5C%E7%AC%94%E8%AE%B0%5Cimgs%5C1546826004438.png" alt="1546826004438"></p><h3 id="直接指针访问"><a href="#直接指针访问" class="headerlink" title="直接指针访问"></a>直接指针访问</h3><p>如果使用直接指针访问，那么Java堆对象的布局中就必须考虑如何放置访问<code>类型数据</code>的相关信息，而reference中存储的直接就是对象地址，如下图所示：</p><p><img src="C:%5CUsers%5Ctenyun%5CDesktop%5C%E6%89%BE%E5%B7%A5%E4%BD%9C%5C%E7%AC%94%E8%AE%B0%5Cimgs%5C1546826074782.png" alt="1546826074782"></p><p>这两种对象访问方式各有优势，使用句柄来访问的最大好处就是reference中存储的是稳定的句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而reference本身不需要修改。 使用直接指针访问方式的最大好处就是速度更快，它节省了一次指针定位的时间开销，由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成本。 </p><p>对于Hotspot而言，使用的是直接指针访问。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> JVM </tag>
            
            <tag> HotSpot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>内存管理重要概念</title>
      <link href="/2019/11/14/java-jvm-1/"/>
      <url>/2019/11/14/java-jvm-1/</url>
      
        <content type="html"><![CDATA[<h1 id="深入理解Java虚拟机读书笔记-1-：内存管理重要概念"><a href="#深入理解Java虚拟机读书笔记-1-：内存管理重要概念" class="headerlink" title="深入理解Java虚拟机读书笔记(1)：内存管理重要概念"></a>深入理解Java虚拟机读书笔记(1)：内存管理重要概念</h1><p>说到Java内存管理，不得不先贴一张非常经典的图，如下所示：</p><p><img src="http://www.rowkey.me/images/blog_images/javamm/java-runtime-memory.jpg" alt="java-runtime-memory.jpg"></p><p>这些模块有些是线程私有的，有的则是线程共享的。下面一一对这些模块进行介绍：</p><h2 id="一、程序计数器"><a href="#一、程序计数器" class="headerlink" title="一、程序计数器"></a>一、程序计数器</h2><p>程序计数器一块比较小的内存空间，可以看做当前线程所执行的字节码的行号指示器，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、 循环、 跳转、 异常处理、 线程恢复等基础功能都需要依赖这个计数器来完成。 </p><p>多线程执行时，实际上是轮流占用处理器来执行的，因此，不可避免的有线程切换，因为任何一个时刻，有且仅有一个线程中的指令占用处理器。为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立<br>的程序计数器，各条线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。 </p><p>当执行的是java代码时，计数器记录的就是正在执行的虚拟机字节码指令的地址；如果是native方法，计数器值为空。</p><p>此处内存区域是<strong>唯一一个</strong>在Java虚拟机规范中没有规定任何内存溢出(OutOfMemoryError)情况的区域。</p><h2 id="二、Java虚拟机栈"><a href="#二、Java虚拟机栈" class="headerlink" title="二、Java虚拟机栈"></a>二、Java虚拟机栈</h2><p>虚拟机栈是线程私有的，它的生命周期和线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个<code>栈帧（Stack Frame）</code>用于存储局部变量表、 操作数栈、 动态链接、 方法出口等信息。 每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。 </p><p>常说的的Java内存区域分为堆内存（Heap）和栈内存(Stack)，这里的<strong>栈</strong>就是虚拟机栈，或者是虚拟机栈中局部变量表的部分。</p><p>所谓局部变量表，顾名思义，其中存放了编译期可以知道的各种基本数据类型（8种基本数据类型）、对象引用（reference类型，它不等同于对象本身，可能是一个<code>指向对象起始地址的引用指针</code>，也可能是<code>指向一个代表对象的句柄或其他与此对象相关的位置</code> ）和returnAddress类型(指向了一条字节码指令的地址 )。<code>局部变量表所需的内存空间在编译期间完成分配</code>，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在<code>方法运行期间不会改变局部变量表的大小</code>。 </p><p>Java虚拟机规范规定了两种此区域会发生的异常：</p><ul><li>StackOverflowError异常：线程请求的栈深度大于虚拟机所允许的深度 </li><li>OutOfMemoryError异常：如果虚拟机栈可以动态扩展（当前大部分虚拟机都可以动态扩展） ，如果扩展时无法申请到足够的内存 </li></ul><h2 id="三、本地方法栈"><a href="#三、本地方法栈" class="headerlink" title="三、本地方法栈"></a>三、本地方法栈</h2><p>本地方法栈（Native Method Stack）与虚拟机栈所发挥的作用是非常相似的，它们之间的区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则为虚拟机使用到的Native方法服务。 </p><p>这个可以说是Java为了妥协而产生的能够调用其他代码的产物，可以不需要深入理解。</p><h2 id="四、Java堆"><a href="#四、Java堆" class="headerlink" title="四、Java堆"></a>四、Java堆</h2><p>Java堆是虚拟机所管理的内存最大的一块，被所有线程所共享，虚拟机启动时自动创建。此内存区域主要目的是存放对象实例。根据Java虚拟机规范中描述，<code>所有的对象实例及数组都要在堆上分配</code>。但是随着技术的发展，JIT编译期日趋成熟，逃逸分析技术（后面介绍）逐渐成熟，栈上分配、标量替换优化技术等，所有对象分配在堆上也不是“绝对”了。</p><p>Java对既然存放了可以说是所有的对象，那么自然而然的，此处是垃圾收集器管理的主要区域。因此有时候Java堆也被称为“GC堆”。大部分的收集器都采用分代收集算法，所以Java堆还可以细分为新生代和老年代。其实还可以更加细分，其目的和作用不过是为了更加方便的跟快的分配和回收内存，与存放的内容无关，存放的都是对象实例。</p><p>Java堆可以是物理上不连续但逻辑上连续的内存空间。</p><h2 id="五、方法区"><a href="#五、方法区" class="headerlink" title="五、方法区"></a>五、方法区</h2><p>方法区也是各个线程共享的内存区域，用于存储已被虚拟机加载的<code>类信息、常量、静态变量、及时编译器编译后的代码</code>等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应该是与Java堆区分开来。 </p><p>对于常见的HotSpot虚拟机来说，方法区又称为“永久代（Permanent Generation)”，其原因是HotSpot虚拟机的设计团队选择<code>把GC分代收集扩展至方法区</code>，或者说<code>使用永久代来实现方法区</code>而已，这样HotSpot的垃圾收集器可以像管理Java堆一样管理这部分内存，能够省去专门为方法区编写内存管理代码的工作。  对于其他虚拟机（如J9和JRockit）来说，不存在永久代的概念。</p><p>目前来看，使用永久代来实现方法区，不是一个好的主意，因为容易遇到内存溢出问题（永久代有-XX：MaxPermSize的上限，J9和JRockit只要没有触碰到进程可用内存的上限，例如32位系统中的4GB，就不会出现问题 ）。在JDK1.7中的HotSpot中，已经把原本放在永久代的字符串常量池移除。</p><p>方法区的管理非常宽松，垃圾收集行为在此区域比较少见。这区域的内存回收目标主要是针对常量池的回收和对类型的卸载，但是类型卸载等条件非常苛刻，所以回收效果很差，但是又必须回收。根据Java虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。 </p><h2 id="六、运行时常量池"><a href="#六、运行时常量池" class="headerlink" title="六、运行时常量池"></a>六、运行时常量池</h2><p>运行时常量池（Runtime Constant Pool）是方法区的一部分。Class文件中除了有类的版本、 字段、 方法、 接口等描述信息外，还有一项信息是常量池（Constant Pool Table），用于存放<code>编译期生成的各种字面量和符号引用</code>，这部分内容将在类加载后进入方法区的运行时常量池中存放。 一般来说，除了保存Class文件中描述的<code>符号引用</code>外，还会把翻译出来的<code>直接引用</code>也存储在运行时常量池中。 </p><p>运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性，Java语言并不要求常量一定只有编译期才能产生，也就是并非预置入Class文件中常量池的内容才能进入方法区运行时常量池，<code>运行期间也可能将新的常量放入池中。</code></p><p>既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出OutOfMemoryError异常。 </p><h2 id="七、直接内存"><a href="#七、直接内存" class="headerlink" title="七、直接内存"></a>七、直接内存</h2><p>直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域。  </p><p>在JDK 1.4中新加入了NIO（New Input/Output）类，引入了一种基于通道（Channel）与缓冲区（Buffer）的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的<code>DirectByteBuffer对象</code>作为这块内存的引用进行操作。 这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。本机直接内存的分配不会受到Java堆大小的限制，但是，既然是内存，肯定还是会受到本机总内存（包括RAM以及SWAP区或者分页文件）大小以及处理器寻址空间的限制。 </p><p> 服务器管理员在配置虚拟机参数时，会根据实际内存设置-Xmx等参数信息，但<code>经常忽略直接内存</code>，使得各个内存区域总和大于物理内存限制（包括物理的和操作系统级的限制），从而导致动态扩展时出现OutOfMemoryError异常。 </p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> JVM </tag>
            
            <tag> 内存管理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>papers-note-14</title>
      <link href="/2019/11/13/papers-note-14/"/>
      <url>/2019/11/13/papers-note-14/</url>
      
        <content type="html"><![CDATA[<h2 id="论文阅读笔记-14"><a href="#论文阅读笔记-14" class="headerlink" title="论文阅读笔记(14)"></a>论文阅读笔记(14)</h2><blockquote><p>论文题目：MARINE: Multi-relational Network Embeddings with Relational Proximity and Node Atributes</p><p>代码公开</p><p>发表于2019，www会议</p></blockquote><h3 id="主要创新点"><a href="#主要创新点" class="headerlink" title="主要创新点"></a>主要创新点</h3><p>对于齐次图和多关系图，提出新的表示学习模型。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> papers </category>
          
      </categories>
      
      
        <tags>
            
            <tag> papers-notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2019/09/21/hello-world/"/>
      <url>/2019/09/21/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class=" language-bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class=" language-bash"><code class="language-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class=" language-bash"><code class="language-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class=" language-bash"><code class="language-bash">$ hexo deploy<span class="token keyword">done</span></code></pre><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
